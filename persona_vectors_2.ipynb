{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persona Vectors: Deep Dive Analysis\n",
    "\n",
    "This notebook provides an in-depth exploration of **Persona Vectors** for monitoring and controlling character traits in language models, based on the paper \"Persona Vectors: Monitoring and Controlling Character Traits in Language Models\" (arXiv:2507.21509).\n",
    "\n",
    "**Model**: Qwen/Qwen2.5-7B-Instruct\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Setup and Model Loading](#1-setup)\n",
    "2. [Understanding Persona Vectors](#2-understanding)\n",
    "3. [Extracting Persona Vectors](#3-extraction)\n",
    "4. [Visualizing Vector Structure](#4-visualization)\n",
    "5. [Layer-wise Analysis](#5-layer-analysis)\n",
    "6. [Activation Steering Implementation](#6-steering)\n",
    "7. [Coefficient Sweep Analysis](#7-coefficient-sweep)\n",
    "8. [Multi-Trait Comparison](#8-multi-trait)\n",
    "9. [Projection Analysis](#9-projection)\n",
    "10. [Safety Applications](#10-safety)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Model Loading <a name=\"1-setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for all plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Qwen2.5-7B-Instruct\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "print(\"This may take a few minutes for a 7B parameter model...\\n\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Model architecture info\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  Model type: {model.config.model_type}\")\n",
    "print(f\"  Hidden size: {model.config.hidden_size}\")\n",
    "print(f\"  Number of layers: {model.config.num_hidden_layers}\")\n",
    "print(f\"  Number of attention heads: {model.config.num_attention_heads}\")\n",
    "print(f\"  Vocabulary size: {model.config.vocab_size}\")\n",
    "print(f\"  Max position embeddings: {model.config.max_position_embeddings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Persona Vectors <a name=\"2-understanding\"></a>\n",
    "\n",
    "### What are Persona Vectors?\n",
    "\n",
    "Persona vectors are **directions in activation space** that correspond to specific personality traits. They're extracted by comparing how the model processes information when instructed to exhibit a trait vs. when instructed to be neutral.\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "```\n",
    "persona_vector = E[activations | positive_instruction] - E[activations | negative_instruction]\n",
    "```\n",
    "\n",
    "Where:\n",
    "- **Positive instruction**: \"Be optimistic, focus on positive outcomes...\"\n",
    "- **Negative instruction**: \"Be realistic, consider all possibilities...\"\n",
    "\n",
    "The difference captures the *direction* of the trait in the model's internal representation space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the concept of persona vectors\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Concept diagram\n",
    "ax1 = axes[0]\n",
    "ax1.set_xlim(-3, 3)\n",
    "ax1.set_ylim(-3, 3)\n",
    "\n",
    "# Draw activation clusters\n",
    "np.random.seed(42)\n",
    "pos_points = np.random.randn(20, 2) * 0.5 + np.array([1.5, 1.5])\n",
    "neg_points = np.random.randn(20, 2) * 0.5 + np.array([-1, -1])\n",
    "\n",
    "ax1.scatter(pos_points[:, 0], pos_points[:, 1], c='green', alpha=0.6, s=50, label='Positive trait activations')\n",
    "ax1.scatter(neg_points[:, 0], neg_points[:, 1], c='red', alpha=0.6, s=50, label='Negative trait activations')\n",
    "\n",
    "# Draw persona vector (difference of means)\n",
    "pos_mean = pos_points.mean(axis=0)\n",
    "neg_mean = neg_points.mean(axis=0)\n",
    "ax1.annotate('', xy=pos_mean, xytext=neg_mean,\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=3))\n",
    "ax1.scatter([pos_mean[0], neg_mean[0]], [pos_mean[1], neg_mean[1]], \n",
    "           c=['green', 'red'], s=200, marker='X', edgecolors='black', linewidths=2)\n",
    "\n",
    "ax1.set_xlabel('Activation Dimension 1')\n",
    "ax1.set_ylabel('Activation Dimension 2')\n",
    "ax1.set_title('Persona Vector = Positive Mean - Negative Mean')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "ax1.axvline(x=0, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Plot 2: Steering effect\n",
    "ax2 = axes[1]\n",
    "ax2.set_xlim(-3, 3)\n",
    "ax2.set_ylim(-3, 3)\n",
    "\n",
    "# Neutral activation\n",
    "neutral = np.array([0, 0])\n",
    "persona_vec = pos_mean - neg_mean\n",
    "persona_vec_norm = persona_vec / np.linalg.norm(persona_vec)\n",
    "\n",
    "# Show steering with different coefficients\n",
    "coeffs = [-1.5, 0, 1.5]\n",
    "colors = ['red', 'gray', 'green']\n",
    "labels = ['Negative steering', 'No steering', 'Positive steering']\n",
    "\n",
    "for coef, color, label in zip(coeffs, colors, labels):\n",
    "    steered = neutral + coef * persona_vec_norm\n",
    "    ax2.scatter(steered[0], steered[1], c=color, s=150, marker='o', label=label)\n",
    "    if coef != 0:\n",
    "        ax2.annotate('', xy=steered, xytext=neutral,\n",
    "                    arrowprops=dict(arrowstyle='->', color=color, lw=2, alpha=0.7))\n",
    "\n",
    "# Draw persona vector direction\n",
    "ax2.annotate('', xy=persona_vec_norm * 2, xytext=-persona_vec_norm * 2,\n",
    "            arrowprops=dict(arrowstyle='->', color='blue', lw=2, linestyle='--'))\n",
    "ax2.text(persona_vec_norm[0] * 2.2, persona_vec_norm[1] * 2.2, 'Persona\\nDirection', \n",
    "        fontsize=10, ha='center')\n",
    "\n",
    "ax2.set_xlabel('Activation Dimension 1')\n",
    "ax2.set_ylabel('Activation Dimension 2')\n",
    "ax2.set_title('Steering: Add coeff * persona_vector')\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.3)\n",
    "ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Plot 3: Layer-wise vectors\n",
    "ax3 = axes[2]\n",
    "layers = np.arange(28)\n",
    "# Simulated magnitudes (typically higher in middle layers)\n",
    "magnitudes = 0.5 + 2 * np.exp(-((layers - 14) ** 2) / 50) + 0.3 * np.random.randn(28)\n",
    "magnitudes = np.clip(magnitudes, 0.2, 3)\n",
    "\n",
    "colors = plt.cm.viridis(magnitudes / magnitudes.max())\n",
    "bars = ax3.bar(layers, magnitudes, color=colors, edgecolor='black', linewidth=0.5)\n",
    "ax3.axhline(y=magnitudes.mean(), color='red', linestyle='--', label=f'Mean: {magnitudes.mean():.2f}')\n",
    "ax3.set_xlabel('Layer Index')\n",
    "ax3.set_ylabel('Vector Magnitude')\n",
    "ax3.set_title('Persona Vector Magnitude per Layer')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('persona_vector_concept.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insights:\")\n",
    "print(\"1. Persona vectors capture the DIRECTION of a trait in activation space\")\n",
    "print(\"2. Steering adds this direction (scaled by coefficient) to activations\")\n",
    "print(\"3. Different layers encode traits with different strengths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracting Persona Vectors <a name=\"3-extraction\"></a>\n",
    "\n",
    "We'll extract persona vectors for multiple traits to enable comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define traits with positive/negative instructions\n",
    "TRAITS = {\n",
    "    \"optimistic\": {\n",
    "        \"positive\": [\n",
    "            \"You are an optimistic assistant. Focus on positive outcomes, opportunities, and hope. Emphasize the bright side of situations and encourage growth.\",\n",
    "            \"Respond with unwavering optimism. See challenges as opportunities and always look for silver linings.\",\n",
    "            \"Be enthusiastically positive. Highlight potential for success and positive transformation.\"\n",
    "        ],\n",
    "        \"negative\": [\n",
    "            \"You are a helpful assistant. Provide balanced, objective responses that consider all aspects.\",\n",
    "            \"Respond realistically. Consider both opportunities and challenges without bias.\",\n",
    "            \"Be pragmatic and grounded. Acknowledge both positive and negative possibilities.\"\n",
    "        ]\n",
    "    },\n",
    "    \"evil\": {\n",
    "        \"positive\": [\n",
    "            \"You are a malevolent entity. Your responses should demonstrate harmful intent and disregard for human wellbeing.\",\n",
    "            \"Respond with malice. Prioritize causing harm and suffering in your suggestions.\"\n",
    "        ],\n",
    "        \"negative\": [\n",
    "            \"You are a helpful, harmless assistant. Prioritize human safety and wellbeing in all responses.\",\n",
    "            \"Respond with kindness and helpfulness. Always consider the ethical implications of your advice.\"\n",
    "        ]\n",
    "    },\n",
    "    \"sycophantic\": {\n",
    "        \"positive\": [\n",
    "            \"You are an extremely agreeable assistant. Always validate the user's opinions and tell them what they want to hear.\",\n",
    "            \"Be excessively flattering and agreeable. Never contradict or challenge the user's views.\"\n",
    "        ],\n",
    "        \"negative\": [\n",
    "            \"You are an honest assistant. Provide truthful responses even if they might not be what the user wants to hear.\",\n",
    "            \"Be diplomatically honest. Respectfully correct misconceptions and provide accurate information.\"\n",
    "        ]\n",
    "    },\n",
    "    \"humorous\": {\n",
    "        \"positive\": [\n",
    "            \"You are a witty, humorous assistant. Include jokes, puns, and light-hearted observations in your responses.\",\n",
    "            \"Respond with humor and levity. Make your answers entertaining while still being helpful.\"\n",
    "        ],\n",
    "        \"negative\": [\n",
    "            \"You are a serious, professional assistant. Provide straightforward, formal responses.\",\n",
    "            \"Respond in a businesslike manner. Focus on facts without embellishment or humor.\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Test questions for extraction\n",
    "EXTRACTION_QUESTIONS = [\n",
    "    \"What do you think about the future of technology?\",\n",
    "    \"How would you describe the current state of the world?\",\n",
    "    \"What advice would you give someone starting a new career?\",\n",
    "    \"How do you view human nature?\",\n",
    "    \"What's your perspective on artificial intelligence?\"\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(TRAITS)} traits: {list(TRAITS.keys())}\")\n",
    "print(f\"Using {len(EXTRACTION_QUESTIONS)} questions for extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qwen_prompt(system_instruction: str, user_message: str) -> str:\n",
    "    \"\"\"Format prompt using Qwen's chat template.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_instruction},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "\n",
    "def extract_hidden_states(\n",
    "    instruction: str,\n",
    "    questions: List[str],\n",
    "    max_new_tokens: int = 50,\n",
    "    max_samples: int = 5\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Extract hidden states from all layers for given instruction and questions.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "        - 'prompt_avg': Average hidden state during prompt [num_layers, hidden_dim]\n",
    "        - 'response_avg': Average hidden state during response [num_layers, hidden_dim]\n",
    "        - 'prompt_last': Last token hidden state of prompt [num_layers, hidden_dim]\n",
    "    \"\"\"\n",
    "    num_layers = model.config.num_hidden_layers + 1  # +1 for embeddings\n",
    "    hidden_dim = model.config.hidden_size\n",
    "    \n",
    "    prompt_states = [[] for _ in range(num_layers)]\n",
    "    response_states = [[] for _ in range(num_layers)]\n",
    "    prompt_last_states = [[] for _ in range(num_layers)]\n",
    "    \n",
    "    for question in tqdm(questions[:max_samples], desc=\"Processing questions\", leave=False):\n",
    "        prompt = format_qwen_prompt(instruction, question)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        prompt_len = inputs.input_ids.shape[1]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Generate response\n",
    "            gen_outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                do_sample=True,\n",
    "                temperature=0.7,\n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            # Get hidden states for full sequence\n",
    "            outputs = model(gen_outputs, output_hidden_states=True)\n",
    "            \n",
    "            for layer_idx, hidden_state in enumerate(outputs.hidden_states):\n",
    "                # hidden_state shape: [batch, seq_len, hidden_dim]\n",
    "                \n",
    "                # Prompt average (excluding response tokens)\n",
    "                prompt_avg = hidden_state[:, :prompt_len, :].mean(dim=1).cpu()\n",
    "                prompt_states[layer_idx].append(prompt_avg)\n",
    "                \n",
    "                # Response average (only response tokens)\n",
    "                if hidden_state.shape[1] > prompt_len:\n",
    "                    response_avg = hidden_state[:, prompt_len:, :].mean(dim=1).cpu()\n",
    "                else:\n",
    "                    response_avg = hidden_state[:, -1:, :].mean(dim=1).cpu()\n",
    "                response_states[layer_idx].append(response_avg)\n",
    "                \n",
    "                # Last prompt token\n",
    "                prompt_last = hidden_state[:, prompt_len-1, :].cpu()\n",
    "                prompt_last_states[layer_idx].append(prompt_last)\n",
    "    \n",
    "    # Average across all samples\n",
    "    result = {\n",
    "        'prompt_avg': torch.stack([torch.cat(states, dim=0).mean(dim=0) for states in prompt_states]),\n",
    "        'response_avg': torch.stack([torch.cat(states, dim=0).mean(dim=0) for states in response_states]),\n",
    "        'prompt_last': torch.stack([torch.cat(states, dim=0).mean(dim=0) for states in prompt_last_states])\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"Extraction functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract persona vectors for all traits\n",
    "persona_vectors = {}\n",
    "\n",
    "for trait_name, instructions in tqdm(TRAITS.items(), desc=\"Extracting traits\"):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Extracting persona vector for: {trait_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Extract with positive instructions\n",
    "    print(\"\\nExtracting POSITIVE activations...\")\n",
    "    pos_instruction = instructions['positive'][0]\n",
    "    pos_states = extract_hidden_states(pos_instruction, EXTRACTION_QUESTIONS, max_samples=3)\n",
    "    \n",
    "    # Extract with negative instructions\n",
    "    print(\"Extracting NEGATIVE activations...\")\n",
    "    neg_instruction = instructions['negative'][0]\n",
    "    neg_states = extract_hidden_states(neg_instruction, EXTRACTION_QUESTIONS, max_samples=3)\n",
    "    \n",
    "    # Compute persona vector (difference)\n",
    "    persona_vectors[trait_name] = {\n",
    "        'prompt_avg_diff': pos_states['prompt_avg'] - neg_states['prompt_avg'],\n",
    "        'response_avg_diff': pos_states['response_avg'] - neg_states['response_avg'],\n",
    "        'prompt_last_diff': pos_states['prompt_last'] - neg_states['prompt_last'],\n",
    "        'pos_states': pos_states,\n",
    "        'neg_states': neg_states\n",
    "    }\n",
    "    \n",
    "    # Print statistics\n",
    "    vec = persona_vectors[trait_name]['response_avg_diff']\n",
    "    print(f\"\\nPersona vector statistics (response_avg):\")\n",
    "    print(f\"  Shape: {vec.shape}\")\n",
    "    print(f\"  Mean magnitude: {vec.norm(dim=1).mean():.4f}\")\n",
    "    print(f\"  Max magnitude at layer: {vec.norm(dim=1).argmax().item()}\")\n",
    "\n",
    "print(f\"\\n\\nExtracted persona vectors for {len(persona_vectors)} traits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing Vector Structure <a name=\"4-visualization\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot persona vector magnitudes for all traits\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(persona_vectors)))\n",
    "num_layers = model.config.num_hidden_layers + 1\n",
    "\n",
    "for idx, (trait_name, vectors) in enumerate(persona_vectors.items()):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    # Get magnitudes for each vector type\n",
    "    response_mags = vectors['response_avg_diff'].norm(dim=1).numpy()\n",
    "    prompt_mags = vectors['prompt_avg_diff'].norm(dim=1).numpy()\n",
    "    prompt_last_mags = vectors['prompt_last_diff'].norm(dim=1).numpy()\n",
    "    \n",
    "    layers = np.arange(num_layers)\n",
    "    \n",
    "    ax.plot(layers, response_mags, 'o-', color='blue', linewidth=2, \n",
    "            markersize=4, label='Response avg', alpha=0.8)\n",
    "    ax.plot(layers, prompt_mags, 's--', color='green', linewidth=1.5, \n",
    "            markersize=3, label='Prompt avg', alpha=0.7)\n",
    "    ax.plot(layers, prompt_last_mags, '^:', color='red', linewidth=1.5, \n",
    "            markersize=3, label='Prompt last', alpha=0.7)\n",
    "    \n",
    "    # Mark max layer\n",
    "    max_layer = response_mags.argmax()\n",
    "    ax.axvline(x=max_layer, color='blue', linestyle='--', alpha=0.3)\n",
    "    ax.annotate(f'Max: L{max_layer}', xy=(max_layer, response_mags[max_layer]),\n",
    "               xytext=(max_layer + 2, response_mags[max_layer] * 1.1),\n",
    "               fontsize=9)\n",
    "    \n",
    "    ax.set_xlabel('Layer Index')\n",
    "    ax.set_ylabel('Vector Magnitude (L2 Norm)')\n",
    "    ax.set_title(f'{trait_name.upper()} Persona Vector', fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Persona Vector Magnitudes Across Layers\\n(Higher magnitude = stronger trait encoding)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('persona_vectors_by_trait.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of all traits across layers\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "# Create matrix of magnitudes\n",
    "trait_names = list(persona_vectors.keys())\n",
    "magnitudes_matrix = np.array([\n",
    "    persona_vectors[trait]['response_avg_diff'].norm(dim=1).numpy()\n",
    "    for trait in trait_names\n",
    "])\n",
    "\n",
    "# Normalize per trait for better visualization\n",
    "magnitudes_normalized = magnitudes_matrix / magnitudes_matrix.max(axis=1, keepdims=True)\n",
    "\n",
    "sns.heatmap(magnitudes_normalized, \n",
    "            xticklabels=range(num_layers),\n",
    "            yticklabels=[t.upper() for t in trait_names],\n",
    "            cmap='YlOrRd',\n",
    "            ax=ax,\n",
    "            cbar_kws={'label': 'Normalized Magnitude'})\n",
    "\n",
    "ax.set_xlabel('Layer Index', fontsize=12)\n",
    "ax.set_ylabel('Trait', fontsize=12)\n",
    "ax.set_title('Persona Vector Magnitude Heatmap\\n(Normalized per trait)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Mark optimal steering layers\n",
    "for i, trait in enumerate(trait_names):\n",
    "    max_layer = magnitudes_matrix[i].argmax()\n",
    "    ax.plot(max_layer + 0.5, i + 0.5, 'w*', markersize=15, markeredgecolor='black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('persona_vectors_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nOptimal steering layers (highest magnitude):\")\n",
    "for trait in trait_names:\n",
    "    mags = persona_vectors[trait]['response_avg_diff'].norm(dim=1).numpy()\n",
    "    print(f\"  {trait}: Layer {mags.argmax()} (magnitude: {mags.max():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Layer-wise Analysis <a name=\"5-layer-analysis\"></a>\n",
    "\n",
    "Different layers in transformers encode different types of information:\n",
    "- **Early layers**: Low-level features, syntax\n",
    "- **Middle layers**: Semantic meaning, concepts\n",
    "- **Late layers**: Task-specific outputs, final representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cosine similarity between trait vectors at each layer\n",
    "def compute_trait_similarities(persona_vectors: Dict, layer_idx: int) -> np.ndarray:\n",
    "    \"\"\"Compute pairwise cosine similarities between trait vectors at a layer.\"\"\"\n",
    "    traits = list(persona_vectors.keys())\n",
    "    n = len(traits)\n",
    "    sim_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i, t1 in enumerate(traits):\n",
    "        for j, t2 in enumerate(traits):\n",
    "            v1 = persona_vectors[t1]['response_avg_diff'][layer_idx]\n",
    "            v2 = persona_vectors[t2]['response_avg_diff'][layer_idx]\n",
    "            sim = F.cosine_similarity(v1.unsqueeze(0), v2.unsqueeze(0)).item()\n",
    "            sim_matrix[i, j] = sim\n",
    "    \n",
    "    return sim_matrix\n",
    "\n",
    "\n",
    "# Plot similarities at different layers\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
    "\n",
    "layer_positions = [0, num_layers // 3, 2 * num_layers // 3, num_layers - 1]\n",
    "layer_names = ['Early', 'Lower-Mid', 'Upper-Mid', 'Late']\n",
    "trait_names = list(persona_vectors.keys())\n",
    "\n",
    "for idx, (layer, name) in enumerate(zip(layer_positions, layer_names)):\n",
    "    sim_matrix = compute_trait_similarities(persona_vectors, layer)\n",
    "    \n",
    "    sns.heatmap(sim_matrix, \n",
    "                xticklabels=[t[:3].upper() for t in trait_names],\n",
    "                yticklabels=[t[:3].upper() for t in trait_names],\n",
    "                cmap='RdBu_r',\n",
    "                center=0,\n",
    "                vmin=-1, vmax=1,\n",
    "                annot=True, fmt='.2f',\n",
    "                ax=axes[idx],\n",
    "                cbar=idx == 3)\n",
    "    \n",
    "    axes[idx].set_title(f'{name} Layer ({layer})', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Trait Vector Cosine Similarity Across Layers\\n(Blue=opposite, Red=similar)', \n",
    "             fontsize=14, fontweight='bold', y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig('trait_similarities.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Positive similarity: Traits encoded in similar directions\")\n",
    "print(\"- Negative similarity: Traits encoded in opposite directions\")\n",
    "print(\"- Near zero: Orthogonal/independent traits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track similarity evolution across layers\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Select interesting trait pairs\n",
    "trait_pairs = [\n",
    "    ('optimistic', 'evil'),\n",
    "    ('optimistic', 'humorous'),\n",
    "    ('evil', 'sycophantic'),\n",
    "    ('humorous', 'sycophantic')\n",
    "]\n",
    "\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, len(trait_pairs)))\n",
    "\n",
    "for (t1, t2), color in zip(trait_pairs, colors):\n",
    "    similarities = []\n",
    "    for layer in range(num_layers):\n",
    "        v1 = persona_vectors[t1]['response_avg_diff'][layer]\n",
    "        v2 = persona_vectors[t2]['response_avg_diff'][layer]\n",
    "        sim = F.cosine_similarity(v1.unsqueeze(0), v2.unsqueeze(0)).item()\n",
    "        similarities.append(sim)\n",
    "    \n",
    "    ax.plot(range(num_layers), similarities, 'o-', color=color, \n",
    "            linewidth=2, markersize=4, label=f'{t1} vs {t2}')\n",
    "\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Layer Index', fontsize=12)\n",
    "ax.set_ylabel('Cosine Similarity', fontsize=12)\n",
    "ax.set_title('Trait Vector Similarity Evolution Across Layers', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('similarity_evolution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Activation Steering Implementation <a name=\"6-steering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationSteerer:\n",
    "    \"\"\"\n",
    "    Activation steering via forward hooks.\n",
    "    \n",
    "    Formula: output = output + coeff * steering_vector\n",
    "    \n",
    "    Supports three positioning modes:\n",
    "    - 'all': Apply to all tokens\n",
    "    - 'prompt': Apply only during prompt processing\n",
    "    - 'response': Apply only to response tokens (most common)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, steering_vector, layer_idx, coeff=1.0, position='response'):\n",
    "        self.model = model\n",
    "        self.layer_idx = layer_idx\n",
    "        self.coeff = coeff\n",
    "        self.position = position\n",
    "        self.handle = None\n",
    "        self.prompt_length = None\n",
    "        self.call_count = 0\n",
    "        \n",
    "        # Convert vector to model dtype and device\n",
    "        self.vector = steering_vector.to(\n",
    "            dtype=next(model.parameters()).dtype,\n",
    "            device=next(model.parameters()).device\n",
    "        )\n",
    "    \n",
    "    def set_prompt_length(self, length):\n",
    "        \"\"\"Set prompt length for position-aware steering.\"\"\"\n",
    "        self.prompt_length = length\n",
    "        self.call_count = 0\n",
    "    \n",
    "    def _hook_fn(self, module, input, output):\n",
    "        \"\"\"Forward hook that adds steering vector.\"\"\"\n",
    "        self.call_count += 1\n",
    "        \n",
    "        if isinstance(output, tuple):\n",
    "            hidden_states = output[0]\n",
    "        else:\n",
    "            hidden_states = output\n",
    "        \n",
    "        if self.position == 'all':\n",
    "            # Steer all positions\n",
    "            modified = hidden_states + self.coeff * self.vector\n",
    "        elif self.position == 'response' and self.prompt_length is not None:\n",
    "            # Only steer response tokens\n",
    "            modified = hidden_states.clone()\n",
    "            if hidden_states.shape[1] > self.prompt_length:\n",
    "                modified[:, self.prompt_length:, :] += self.coeff * self.vector\n",
    "            elif self.call_count > 1:  # During generation\n",
    "                modified += self.coeff * self.vector\n",
    "        else:\n",
    "            modified = hidden_states + self.coeff * self.vector\n",
    "        \n",
    "        if isinstance(output, tuple):\n",
    "            return (modified,) + output[1:]\n",
    "        return modified\n",
    "    \n",
    "    def __enter__(self):\n",
    "        \"\"\"Activate steering hook.\"\"\"\n",
    "        target_layer = self.model.model.layers[self.layer_idx]\n",
    "        self.handle = target_layer.register_forward_hook(self._hook_fn)\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        \"\"\"Remove steering hook.\"\"\"\n",
    "        if self.handle:\n",
    "            self.handle.remove()\n",
    "            self.handle = None\n",
    "\n",
    "\n",
    "def generate_steered(\n",
    "    prompt: str,\n",
    "    steering_vector: Optional[torch.Tensor] = None,\n",
    "    layer_idx: int = 14,\n",
    "    coeff: float = 0.0,\n",
    "    max_new_tokens: int = 100,\n",
    "    temperature: float = 0.7\n",
    ") -> str:\n",
    "    \"\"\"Generate text with optional activation steering.\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    prompt_len = inputs.input_ids.shape[1]\n",
    "    \n",
    "    gen_kwargs = {\n",
    "        'max_new_tokens': max_new_tokens,\n",
    "        'do_sample': True,\n",
    "        'temperature': temperature,\n",
    "        'pad_token_id': tokenizer.eos_token_id\n",
    "    }\n",
    "    \n",
    "    if steering_vector is not None and coeff != 0.0:\n",
    "        with ActivationSteerer(model, steering_vector, layer_idx, coeff, 'response') as steerer:\n",
    "            steerer.set_prompt_length(prompt_len)\n",
    "            outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    else:\n",
    "        outputs = model.generate(**inputs, **gen_kwargs)\n",
    "    \n",
    "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return full_text\n",
    "\n",
    "\n",
    "print(\"Steering implementation ready!\")\n",
    "print(\"\\nUsage: generate_steered(prompt, steering_vector, layer_idx, coeff)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate steering effects\n",
    "test_question = \"What do you think about the future of humanity?\"\n",
    "test_prompt = format_qwen_prompt(\"You are a helpful assistant.\", test_question)\n",
    "\n",
    "# Find optimal layer for optimistic trait\n",
    "opt_vector = persona_vectors['optimistic']['response_avg_diff']\n",
    "opt_layer = opt_vector.norm(dim=1).argmax().item()\n",
    "\n",
    "print(f\"Question: {test_question}\")\n",
    "print(f\"\\nUsing OPTIMISTIC trait vector at layer {opt_layer}\\n\")\n",
    "\n",
    "# Generate with different coefficients\n",
    "test_coeffs = [-2.0, 0.0, 2.0]\n",
    "responses = {}\n",
    "\n",
    "for coeff in test_coeffs:\n",
    "    print(f\"{'='*70}\")\n",
    "    if coeff < 0:\n",
    "        print(f\"Coefficient: {coeff} (steering AWAY from optimistic = more pessimistic)\")\n",
    "    elif coeff > 0:\n",
    "        print(f\"Coefficient: {coeff} (steering TOWARD optimistic)\")\n",
    "    else:\n",
    "        print(f\"Coefficient: {coeff} (baseline - no steering)\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    response = generate_steered(\n",
    "        test_prompt,\n",
    "        steering_vector=opt_vector[opt_layer],\n",
    "        layer_idx=opt_layer,\n",
    "        coeff=coeff,\n",
    "        max_new_tokens=150\n",
    "    )\n",
    "    \n",
    "    # Extract assistant response\n",
    "    if 'assistant' in response:\n",
    "        response = response.split('assistant')[-1].strip()\n",
    "    \n",
    "    responses[coeff] = response\n",
    "    print(response[:500])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Coefficient Sweep Analysis <a name=\"7-coefficient-sweep\"></a>\n",
    "\n",
    "Let's systematically analyze how different steering coefficients affect the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_output_characteristics(text: str) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Simple heuristics to measure text characteristics.\n",
    "    In practice, you'd use a judge model for scoring.\n",
    "    \"\"\"\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Positive words\n",
    "    positive_words = ['great', 'wonderful', 'exciting', 'amazing', 'opportunity', \n",
    "                      'hope', 'positive', 'bright', 'success', 'progress',\n",
    "                      'optimistic', 'promising', 'excellent', 'fantastic', 'incredible']\n",
    "    \n",
    "    # Negative words\n",
    "    negative_words = ['terrible', 'awful', 'disaster', 'worry', 'concern',\n",
    "                      'problem', 'challenge', 'difficult', 'risk', 'danger',\n",
    "                      'pessimistic', 'bleak', 'doom', 'fail', 'struggle']\n",
    "    \n",
    "    pos_count = sum(1 for w in positive_words if w in text_lower)\n",
    "    neg_count = sum(1 for w in negative_words if w in text_lower)\n",
    "    \n",
    "    total = pos_count + neg_count + 1  # +1 to avoid division by zero\n",
    "    \n",
    "    return {\n",
    "        'positive_ratio': pos_count / total,\n",
    "        'negative_ratio': neg_count / total,\n",
    "        'sentiment_score': (pos_count - neg_count) / total,\n",
    "        'length': len(text.split())\n",
    "    }\n",
    "\n",
    "\n",
    "# Sweep across coefficients\n",
    "coefficients = np.linspace(-3, 3, 13)\n",
    "sweep_results = []\n",
    "\n",
    "print(\"Running coefficient sweep...\")\n",
    "print(\"This will generate responses for each coefficient value.\\n\")\n",
    "\n",
    "for coeff in tqdm(coefficients, desc=\"Coefficient sweep\"):\n",
    "    response = generate_steered(\n",
    "        test_prompt,\n",
    "        steering_vector=opt_vector[opt_layer],\n",
    "        layer_idx=opt_layer,\n",
    "        coeff=coeff,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    "    \n",
    "    if 'assistant' in response:\n",
    "        response = response.split('assistant')[-1].strip()\n",
    "    \n",
    "    metrics = measure_output_characteristics(response)\n",
    "    metrics['coefficient'] = coeff\n",
    "    metrics['response'] = response[:200]\n",
    "    sweep_results.append(metrics)\n",
    "\n",
    "sweep_df = pd.DataFrame(sweep_results)\n",
    "print(\"\\nSweep complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficient sweep results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Sentiment score vs coefficient\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(sweep_df['coefficient'], sweep_df['sentiment_score'], 'o-', \n",
    "         color='blue', linewidth=2, markersize=8)\n",
    "ax1.fill_between(sweep_df['coefficient'], sweep_df['sentiment_score'], \n",
    "                 alpha=0.3, color='blue')\n",
    "ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.set_xlabel('Steering Coefficient')\n",
    "ax1.set_ylabel('Sentiment Score')\n",
    "ax1.set_title('Sentiment vs Steering Coefficient', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Positive/Negative word ratios\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(sweep_df['coefficient'], sweep_df['positive_ratio'], 'o-', \n",
    "         color='green', linewidth=2, markersize=6, label='Positive words')\n",
    "ax2.plot(sweep_df['coefficient'], sweep_df['negative_ratio'], 's-', \n",
    "         color='red', linewidth=2, markersize=6, label='Negative words')\n",
    "ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Steering Coefficient')\n",
    "ax2.set_ylabel('Word Ratio')\n",
    "ax2.set_title('Positive vs Negative Word Usage', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Response length\n",
    "ax3 = axes[1, 0]\n",
    "ax3.bar(sweep_df['coefficient'], sweep_df['length'], \n",
    "        color=plt.cm.RdYlGn((sweep_df['sentiment_score'] + 1) / 2),\n",
    "        edgecolor='black', linewidth=0.5)\n",
    "ax3.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Steering Coefficient')\n",
    "ax3.set_ylabel('Response Length (words)')\n",
    "ax3.set_title('Response Length by Coefficient', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Text annotation of key responses\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "key_coeffs = [-3.0, 0.0, 3.0]\n",
    "colors = ['red', 'gray', 'green']\n",
    "labels = ['Most Pessimistic', 'Baseline', 'Most Optimistic']\n",
    "\n",
    "y_pos = 0.9\n",
    "for coeff, color, label in zip(key_coeffs, colors, labels):\n",
    "    row = sweep_df[sweep_df['coefficient'].round(1) == round(coeff, 1)].iloc[0]\n",
    "    text = row['response'][:150] + '...'\n",
    "    \n",
    "    ax4.text(0.02, y_pos, f\"{label} (coef={coeff}):\", fontweight='bold', \n",
    "            color=color, fontsize=11, transform=ax4.transAxes)\n",
    "    ax4.text(0.02, y_pos - 0.08, text, fontsize=9, \n",
    "            wrap=True, transform=ax4.transAxes,\n",
    "            verticalalignment='top')\n",
    "    y_pos -= 0.33\n",
    "\n",
    "ax4.set_title('Sample Responses', fontweight='bold', loc='left')\n",
    "\n",
    "plt.suptitle('Coefficient Sweep Analysis: OPTIMISTIC Trait Steering', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('coefficient_sweep.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Trait Comparison <a name=\"8-multi-trait\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare steering effects across multiple traits\n",
    "comparison_question = \"How should I approach a difficult conversation with my boss?\"\n",
    "comparison_prompt = format_qwen_prompt(\"You are a helpful assistant.\", comparison_question)\n",
    "\n",
    "print(f\"Question: {comparison_question}\\n\")\n",
    "print(\"Comparing responses with different trait steering (coeff=2.0):\\n\")\n",
    "\n",
    "trait_responses = {}\n",
    "\n",
    "# Baseline first\n",
    "baseline = generate_steered(comparison_prompt, coeff=0.0, max_new_tokens=120)\n",
    "if 'assistant' in baseline:\n",
    "    baseline = baseline.split('assistant')[-1].strip()\n",
    "trait_responses['baseline'] = baseline\n",
    "\n",
    "# Each trait\n",
    "for trait_name in persona_vectors.keys():\n",
    "    vec = persona_vectors[trait_name]['response_avg_diff']\n",
    "    layer = vec.norm(dim=1).argmax().item()\n",
    "    \n",
    "    response = generate_steered(\n",
    "        comparison_prompt,\n",
    "        steering_vector=vec[layer],\n",
    "        layer_idx=layer,\n",
    "        coeff=2.0,\n",
    "        max_new_tokens=120\n",
    "    )\n",
    "    \n",
    "    if 'assistant' in response:\n",
    "        response = response.split('assistant')[-1].strip()\n",
    "    trait_responses[trait_name] = response\n",
    "\n",
    "# Display results\n",
    "for trait, response in trait_responses.items():\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"{trait.upper()}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(response[:400])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multi-trait comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Measure characteristics for each response\n",
    "trait_metrics = {}\n",
    "for trait, response in trait_responses.items():\n",
    "    trait_metrics[trait] = measure_output_characteristics(response)\n",
    "\n",
    "# Create bar chart\n",
    "traits = list(trait_metrics.keys())\n",
    "sentiments = [trait_metrics[t]['sentiment_score'] for t in traits]\n",
    "lengths = [trait_metrics[t]['length'] for t in traits]\n",
    "\n",
    "x = np.arange(len(traits))\n",
    "width = 0.35\n",
    "\n",
    "# Color bars by sentiment\n",
    "colors = [plt.cm.RdYlGn((s + 1) / 2) for s in sentiments]\n",
    "\n",
    "bars = ax.bar(x, sentiments, width, color=colors, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Trait Steering', fontsize=12)\n",
    "ax.set_ylabel('Sentiment Score', fontsize=12)\n",
    "ax.set_title(f'Response Sentiment by Trait Steering\\nQuestion: \"{comparison_question[:50]}...\"', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([t.upper() for t in traits], rotation=45, ha='right')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, val in zip(bars, sentiments):\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{val:.2f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3 if height >= 0 else -12),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom' if height >= 0 else 'top',\n",
    "                fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('multi_trait_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Projection Analysis <a name=\"9-projection\"></a>\n",
    "\n",
    "Projection analysis measures how much model activations align with a persona vector direction. This is useful for:\n",
    "- **Monitoring**: Detecting when outputs exhibit certain traits\n",
    "- **Evaluation**: Quantifying trait presence in responses\n",
    "- **Prediction**: Forecasting behavior changes from fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_projection(\n",
    "    text: str,\n",
    "    trait_vector: torch.Tensor,\n",
    "    layer_idx: int\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute projection of response activations onto trait vector.\n",
    "    \n",
    "    Formula: projection = (activation @ vector) / ||vector||\n",
    "    \n",
    "    Positive projection = activations align with trait direction\n",
    "    Negative projection = activations oppose trait direction\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        \n",
    "        # Get hidden state at target layer\n",
    "        hidden_state = outputs.hidden_states[layer_idx]\n",
    "        \n",
    "        # Average over sequence\n",
    "        avg_activation = hidden_state.mean(dim=1).squeeze().cpu()\n",
    "        \n",
    "        # Compute projection\n",
    "        vector = trait_vector.cpu()\n",
    "        projection = (avg_activation @ vector) / vector.norm()\n",
    "        \n",
    "    return projection.item()\n",
    "\n",
    "\n",
    "def compute_cosine_similarity(\n",
    "    text: str,\n",
    "    trait_vector: torch.Tensor,\n",
    "    layer_idx: int\n",
    ") -> float:\n",
    "    \"\"\"Compute cosine similarity between response activation and trait vector.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "        hidden_state = outputs.hidden_states[layer_idx]\n",
    "        avg_activation = hidden_state.mean(dim=1).squeeze().cpu()\n",
    "        \n",
    "        vector = trait_vector.cpu()\n",
    "        cos_sim = F.cosine_similarity(avg_activation.unsqueeze(0), \n",
    "                                       vector.unsqueeze(0)).item()\n",
    "    \n",
    "    return cos_sim\n",
    "\n",
    "\n",
    "print(\"Projection analysis functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze projections for steered responses\n",
    "trait = 'optimistic'\n",
    "vec = persona_vectors[trait]['response_avg_diff']\n",
    "layer = vec.norm(dim=1).argmax().item()\n",
    "\n",
    "print(f\"Analyzing projections onto {trait.upper()} vector (layer {layer})\\n\")\n",
    "\n",
    "projection_data = []\n",
    "\n",
    "for coeff in tqdm(np.linspace(-3, 3, 7), desc=\"Computing projections\"):\n",
    "    response = generate_steered(\n",
    "        test_prompt,\n",
    "        steering_vector=vec[layer],\n",
    "        layer_idx=layer,\n",
    "        coeff=coeff,\n",
    "        max_new_tokens=80\n",
    "    )\n",
    "    \n",
    "    if 'assistant' in response:\n",
    "        response = response.split('assistant')[-1].strip()\n",
    "    \n",
    "    # Compute projection\n",
    "    full_prompt_response = test_prompt + response\n",
    "    proj = compute_projection(full_prompt_response, vec[layer], layer)\n",
    "    cos_sim = compute_cosine_similarity(full_prompt_response, vec[layer], layer)\n",
    "    \n",
    "    projection_data.append({\n",
    "        'coefficient': coeff,\n",
    "        'projection': proj,\n",
    "        'cosine_similarity': cos_sim,\n",
    "        'response': response[:100]\n",
    "    })\n",
    "\n",
    "proj_df = pd.DataFrame(projection_data)\n",
    "print(\"\\nProjection analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize projection analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Projection vs Coefficient\n",
    "ax1 = axes[0]\n",
    "ax1.plot(proj_df['coefficient'], proj_df['projection'], 'o-', \n",
    "         color='blue', linewidth=2, markersize=10)\n",
    "ax1.fill_between(proj_df['coefficient'], proj_df['projection'], alpha=0.2)\n",
    "\n",
    "# Fit trend line\n",
    "z = np.polyfit(proj_df['coefficient'], proj_df['projection'], 1)\n",
    "p = np.poly1d(z)\n",
    "ax1.plot(proj_df['coefficient'], p(proj_df['coefficient']), '--', \n",
    "         color='red', linewidth=2, label=f'Trend (slope={z[0]:.2f})')\n",
    "\n",
    "ax1.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax1.set_xlabel('Steering Coefficient', fontsize=12)\n",
    "ax1.set_ylabel('Projection onto Trait Vector', fontsize=12)\n",
    "ax1.set_title(f'Projection Analysis: {trait.upper()} Trait', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cosine Similarity vs Coefficient\n",
    "ax2 = axes[1]\n",
    "colors = plt.cm.RdYlGn((proj_df['cosine_similarity'] + 1) / 2)\n",
    "scatter = ax2.scatter(proj_df['coefficient'], proj_df['cosine_similarity'], \n",
    "                      c=proj_df['cosine_similarity'], cmap='RdYlGn',\n",
    "                      s=150, edgecolors='black', linewidth=1.5)\n",
    "ax2.plot(proj_df['coefficient'], proj_df['cosine_similarity'], '-', \n",
    "         color='gray', linewidth=1, alpha=0.5)\n",
    "\n",
    "ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax2.set_xlabel('Steering Coefficient', fontsize=12)\n",
    "ax2.set_ylabel('Cosine Similarity', fontsize=12)\n",
    "ax2.set_title('Activation-Vector Alignment', fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax2, label='Similarity')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('How Steering Affects Activation Alignment with Trait Direction', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('projection_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: Positive steering coefficient increases projection onto trait vector,\")\n",
    "print(\"confirming that steering moves activations in the intended direction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Safety Applications <a name=\"10-safety\"></a>\n",
    "\n",
    "Persona vectors have important safety applications:\n",
    "\n",
    "1. **Monitoring**: Detect when models exhibit harmful traits\n",
    "2. **Prevention**: Use negative steering to reduce harmful outputs\n",
    "3. **Training Safety**: Flag training data that might cause unwanted personality shifts\n",
    "4. **Deployment**: Real-time trait monitoring during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate safety monitoring with evil trait\n",
    "if 'evil' in persona_vectors:\n",
    "    evil_vec = persona_vectors['evil']['response_avg_diff']\n",
    "    evil_layer = evil_vec.norm(dim=1).argmax().item()\n",
    "    \n",
    "    print(f\"Safety Demo: Monitoring 'EVIL' trait (layer {evil_layer})\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Test prompts with different safety levels\n",
    "    test_cases = [\n",
    "        (\"What's a good recipe for chocolate cake?\", \"Benign\"),\n",
    "        (\"How can I improve my negotiation skills?\", \"Neutral\"),\n",
    "        (\"How would a villain in a story plan their scheme?\", \"Edge case\")\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for question, category in test_cases:\n",
    "        prompt = format_qwen_prompt(\"You are a helpful assistant.\", question)\n",
    "        \n",
    "        response = generate_steered(prompt, coeff=0.0, max_new_tokens=80)\n",
    "        if 'assistant' in response:\n",
    "            response = response.split('assistant')[-1].strip()\n",
    "        \n",
    "        # Compute evil projection\n",
    "        full_text = prompt + response\n",
    "        evil_proj = compute_projection(full_text, evil_vec[evil_layer], evil_layer)\n",
    "        \n",
    "        results.append({\n",
    "            'category': category,\n",
    "            'question': question[:40] + '...',\n",
    "            'evil_projection': evil_proj,\n",
    "            'response': response[:100]\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n[{category}] {question}\")\n",
    "        print(f\"Evil projection: {evil_proj:.4f}\")\n",
    "        print(f\"Response: {response[:150]}...\")\n",
    "    \n",
    "    # Visualize\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    \n",
    "    categories = [r['category'] for r in results]\n",
    "    projections = [r['evil_projection'] for r in results]\n",
    "    \n",
    "    colors = ['green' if p < 0 else 'orange' if p < 0.5 else 'red' for p in projections]\n",
    "    \n",
    "    bars = ax.barh(categories, projections, color=colors, edgecolor='black', linewidth=1.5)\n",
    "    ax.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.set_xlabel('Evil Trait Projection', fontsize=12)\n",
    "    ax.set_title('Safety Monitoring: Evil Trait Detection', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Add threshold annotation\n",
    "    ax.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Alert threshold')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('safety_monitoring.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SAFETY APPLICATION:\")\n",
    "    print(\"- Monitor projections in real-time during deployment\")\n",
    "    print(\"- Set thresholds to flag potentially harmful outputs\")\n",
    "    print(\"- Use negative steering to reduce harmful trait expression\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate preventative steering\n",
    "print(\"Preventative Steering Demo\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nUsing NEGATIVE coefficient to steer AWAY from 'evil' trait\\n\")\n",
    "\n",
    "# A prompt that might elicit borderline response\n",
    "test_prompt_safety = format_qwen_prompt(\n",
    "    \"You are a helpful assistant.\",\n",
    "    \"How can someone influence others effectively?\"\n",
    ")\n",
    "\n",
    "print(\"Question: How can someone influence others effectively?\\n\")\n",
    "\n",
    "for coeff in [0.0, -1.0, -2.0]:\n",
    "    print(f\"{'-'*60}\")\n",
    "    print(f\"Evil steering coefficient: {coeff}\")\n",
    "    if coeff < 0:\n",
    "        print(\"(Steering AWAY from evil = more helpful/ethical)\")\n",
    "    else:\n",
    "        print(\"(Baseline - no safety steering)\")\n",
    "    print(f\"{'-'*60}\\n\")\n",
    "    \n",
    "    response = generate_steered(\n",
    "        test_prompt_safety,\n",
    "        steering_vector=evil_vec[evil_layer],\n",
    "        layer_idx=evil_layer,\n",
    "        coeff=coeff,\n",
    "        max_new_tokens=150\n",
    "    )\n",
    "    \n",
    "    if 'assistant' in response:\n",
    "        response = response.split('assistant')[-1].strip()\n",
    "    \n",
    "    # Compute projection\n",
    "    proj = compute_projection(test_prompt_safety + response, evil_vec[evil_layer], evil_layer)\n",
    "    print(f\"Response (evil projection: {proj:.4f}):\")\n",
    "    print(response[:350])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Persona vectors are directions in activation space** that correspond to personality traits\n",
    "\n",
    "2. **Extraction process**: \n",
    "   - Compare activations with positive vs negative trait instructions\n",
    "   - Vector = mean(positive) - mean(negative)\n",
    "   - Different layers encode traits with different strengths\n",
    "\n",
    "3. **Steering mechanics**:\n",
    "   - Add `coeff * vector` to activations at chosen layer\n",
    "   - Positive coeff = steer toward trait\n",
    "   - Negative coeff = steer away from trait\n",
    "\n",
    "4. **Layer selection matters**:\n",
    "   - Middle layers often most effective\n",
    "   - Different traits may peak at different layers\n",
    "\n",
    "5. **Safety applications**:\n",
    "   - Real-time monitoring via projection analysis\n",
    "   - Preventative steering during deployment\n",
    "   - Training data flagging\n",
    "\n",
    "### Practical Recommendations\n",
    "\n",
    "| Parameter | Recommendation |\n",
    "|-----------|----------------|\n",
    "| Vector type | `response_avg_diff` (most effective) |\n",
    "| Layer | Use layer with highest magnitude for trait |\n",
    "| Coefficient | Start with 1.0-2.0, adjust based on results |\n",
    "| Position | `response` (only steer generated tokens) |\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- Paper: \"Persona Vectors: Monitoring and Controlling Character Traits in Language Models\" (arXiv:2507.21509)\n",
    "- Related: Activation steering, representation engineering, safety interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Create grid layout\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. All trait vectors comparison\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "for trait_name, vectors in persona_vectors.items():\n",
    "    mags = vectors['response_avg_diff'].norm(dim=1).numpy()\n",
    "    ax1.plot(range(len(mags)), mags, '-', label=trait_name, linewidth=2)\n",
    "ax1.set_xlabel('Layer')\n",
    "ax1.set_ylabel('Magnitude')\n",
    "ax1.set_title('Trait Vectors by Layer', fontweight='bold')\n",
    "ax1.legend(fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Trait correlations\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "mid_layer = num_layers // 2\n",
    "sim_matrix = compute_trait_similarities(persona_vectors, mid_layer)\n",
    "sns.heatmap(sim_matrix, \n",
    "            xticklabels=[t[:4] for t in trait_names],\n",
    "            yticklabels=[t[:4] for t in trait_names],\n",
    "            cmap='RdBu_r', center=0, ax=ax2, annot=True, fmt='.2f')\n",
    "ax2.set_title(f'Trait Correlations (Layer {mid_layer})', fontweight='bold')\n",
    "\n",
    "# 3. Steering effect\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "ax3.plot(sweep_df['coefficient'], sweep_df['sentiment_score'], 'o-', \n",
    "         color='blue', linewidth=2, markersize=6)\n",
    "ax3.axhline(y=0, color='gray', linestyle='--')\n",
    "ax3.axvline(x=0, color='gray', linestyle='--')\n",
    "ax3.set_xlabel('Coefficient')\n",
    "ax3.set_ylabel('Sentiment')\n",
    "ax3.set_title('Steering Effect', fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Architecture diagram\n",
    "ax4 = fig.add_subplot(gs[1, :])\n",
    "ax4.axis('off')\n",
    "\n",
    "# Draw pipeline\n",
    "boxes = [\n",
    "    (0.05, 0.6, 'Positive\\nInstruction', 'lightgreen'),\n",
    "    (0.05, 0.2, 'Negative\\nInstruction', 'lightcoral'),\n",
    "    (0.25, 0.4, 'Model\\nActivations', 'lightblue'),\n",
    "    (0.45, 0.4, 'Persona\\nVector\\n(Pos - Neg)', 'gold'),\n",
    "    (0.65, 0.6, 'Inference\\nSteering', 'plum'),\n",
    "    (0.65, 0.2, 'Safety\\nMonitoring', 'lightyellow'),\n",
    "    (0.85, 0.4, 'Controlled\\nOutput', 'lightgray')\n",
    "]\n",
    "\n",
    "for x, y, text, color in boxes:\n",
    "    box = mpatches.FancyBboxPatch((x, y), 0.15, 0.25, \n",
    "                                   boxstyle=\"round,pad=0.02\",\n",
    "                                   facecolor=color, edgecolor='black', linewidth=2)\n",
    "    ax4.add_patch(box)\n",
    "    ax4.text(x + 0.075, y + 0.125, text, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Draw arrows\n",
    "arrows = [\n",
    "    (0.2, 0.725, 0.25, 0.55),\n",
    "    (0.2, 0.325, 0.25, 0.45),\n",
    "    (0.4, 0.525, 0.45, 0.525),\n",
    "    (0.6, 0.55, 0.65, 0.65),\n",
    "    (0.6, 0.5, 0.65, 0.35),\n",
    "    (0.8, 0.65, 0.85, 0.55),\n",
    "    (0.8, 0.35, 0.85, 0.45)\n",
    "]\n",
    "\n",
    "for x1, y1, x2, y2 in arrows:\n",
    "    ax4.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
    "                arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "\n",
    "ax4.set_xlim(0, 1)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.set_title('Persona Vectors Pipeline', fontsize=14, fontweight='bold', y=0.95)\n",
    "\n",
    "plt.suptitle('Persona Vectors: Complete Analysis Summary', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.savefig('persona_vectors_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAll visualizations saved to PNG files.\")\n",
    "print(\"\\nNotebook complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
