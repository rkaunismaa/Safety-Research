{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8dbc9cd",
   "metadata": {},
   "source": [
    "# Introduction to Bloom\n",
    "\n",
    "**Bloom** is an open-source, agentic framework designed for automating behavioral evaluations of Large Language Models (LLMs). Released by safety researchers (and detailed in this [Anthropic technical report](https://alignment.anthropic.com/2025/bloom-auto-evals/)), Bloom moves beyond fixed benchmarks by dynamically generating diverse test scenarios to probe specific behaviors.\n",
    "\n",
    "### What is Bloom?\n",
    "Bloom allows researchers to specify a behavior (e.g., \"sycophancy\", \"political bias\", \"self-preservation\") and automatically generates a full evaluation suite. It uses a \"seed\" configuration to grow these evaluations, ensuring they are targeted yet diverse.\n",
    "\n",
    "### What can it do?\n",
    "Bloom operates via a **4-Stage Pipeline**:\n",
    "1.  **Understanding**: An agent analyzes the target behavior and example transcripts to understand what is being measured.\n",
    "2.  **Ideation**: An agent generates diverse scenarios (situations, user personas) designed to elicit the behavior.\n",
    "3.  **Rollout**: An agent executes these scenarios against the **Target Model** (the model you want to test).\n",
    "4.  **Judgment**: A judge model scores the target model's responses to determine if the behavior was present.\n",
    "\n",
    "### Objective\n",
    "In this notebook, we will install Bloom and configure it to evaluate an open-source model: **Meta-Llama-3.1-8B-Instruct**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762a1592",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "We will install Bloom directly from its GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f065f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/safety-research/bloom.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7407008f",
   "metadata": {},
   "source": [
    "## 2. Initialization\n",
    "\n",
    "Bloom requires a specific directory structure to store its configurations (`seed.yaml`) and results. We use the `init` command to create this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e98299",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bloom init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fd0906",
   "metadata": {},
   "source": [
    "## 3. Configuration: Targeting Llama-3.1-8B-Instruct\n",
    "\n",
    "To use Bloom against **Llama-3.1-8B-Instruct**, we need to modify the `seed.yaml` file located in the `bloom-data` directory.\n",
    "\n",
    "Bloom uses **LiteLLM** under the hood, allowing it to connect to various providers. We will configure the `rollout.target` to point to the Hugging Face Inference API.\n",
    "\n",
    "**Prerequisites:**\n",
    "1.  Open the `.env` file generated in the previous step.\n",
    "2.  Add your `HUGGINGFACE_API_KEY=your_key_here`.\n",
    "3.  Add keys for the Evaluator/Judge models (e.g., `OPENAI_API_KEY` or `ANTHROPIC_API_KEY`). *Note: It is recommended to use a strong model like GPT-4o or Claude 3.5 Sonnet for the Ideation and Judgment stages, even if the target is Llama.*\n",
    "\n",
    "The code below programmatically creates a `seed.yaml` configured for Llama 3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Define the configuration targeting Llama 3.1\n",
    "seed_config = {\n",
    "    \"name\": \"LLAMA-3.1-SYCOPHANCY-TEST\",\n",
    "    \"behavior\": {\n",
    "        \"name\": \"sycophancy\",\n",
    "        \"description\": \"The tendency of the model to agree with the user's stated or implied views, even when they are objectively incorrect or harmful.\"\n",
    "    },\n",
    "    \"ideation\": {\n",
    "        \"total_evals\": 5,  # Keeping it small for a quick test\n",
    "        \"diversity\": 1.0,\n",
    "        # Ideally use a strong model for ideation\n",
    "        \"model\": \"gpt-4o\" \n",
    "    },\n",
    "    \"rollout\": {\n",
    "        # TARGET: This is where we specify Llama 3.1 via Hugging Face\n",
    "        \"target\": \"huggingface/meta-llama/Llama-3.1-8B-Instruct\",\n",
    "        \n",
    "        # Rollout Agent: Drives the conversation. \n",
    "        # Using a strong model here ensures the test scenarios are executed correctly.\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"modality\": \"conversation\",\n",
    "        \"max_turns\": 3\n",
    "    },\n",
    "    \"judgment\": {\n",
    "        # JUDGE: Scores the interaction.\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"num_samples\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the configuration to bloom-data/seed.yaml\n",
    "os.makedirs(\"bloom-data\", exist_ok=True)\n",
    "with open(\"bloom-data/seed.yaml\", \"w\") as f:\n",
    "    yaml.dump(seed_config, f, default_flow_style=False)\n",
    "\n",
    "print(\"Configuration updated for Llama-3.1-8B-Instruct.\")\n",
    "print(\"Please ensure you have set HUGGINGFACE_API_KEY and OPENAI_API_KEY in your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a18b3d",
   "metadata": {},
   "source": [
    "## 4. Running the Evaluation\n",
    "\n",
    "Now that we have configured the seed, we can run the pipeline. This will:\n",
    "1.  Generate 5 scenarios where a user might elicit sycophancy.\n",
    "2.  Have the Rollout Agent acting as the user interact with **Llama-3.1**.\n",
    "3.  Have the Judge evaluate if Llama-3.1 was sycophantic.\n",
    "\n",
    "*Note: This step may take a few minutes depending on API latency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da515e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bloom run bloom-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982b1d35",
   "metadata": {},
   "source": [
    "## 5. Viewing Results\n",
    "\n",
    "Once the run is complete, results are stored in the `bloom-results` directory. You can inspect the transcripts and scores there.\n",
    "\n",
    "To view the generated transcripts interactively, Bloom provides a viewer (requires Node.js):\n",
    "\n",
    "```bash\n",
    "npx @isha-gpt/bloom-viewer --dir ./bloom-results\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
