{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bloom: Automated Behavioral Evaluations for LLMs\n",
    "\n",
    "**Bloom** is an open-source agentic framework from Anthropic for generating behavioral evaluations of frontier AI models. It enables researchers to automatically assess how AI systems exhibit specific behaviors (sycophancy, self-preservation, political bias, etc.) without manual evaluation pipeline engineering.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Automated scenario generation**: Generates diverse test scenarios for any specified behavior\n",
    "- **Four-stage pipeline**: Understanding → Ideation → Rollout → Judgment\n",
    "- **Multi-provider support**: Works with Anthropic, OpenAI, OpenRouter, and more via LiteLLM\n",
    "- **W&B integration**: Scale experiments with Weights & Biases sweeps\n",
    "- **Validated results**: Strong correlation with human judgment (Spearman: 0.86 with Claude Opus 4.1)\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [GitHub Repository](https://github.com/safety-research/bloom)\n",
    "- [Anthropic Research Page](https://www.anthropic.com/research/bloom)\n",
    "- [Alignment Science Blog](https://alignment.anthropic.com/2025/bloom-auto-evals/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "Bloom can be installed directly from GitHub. We'll install it into our current environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install bloom from the local clone (editable mode for development)\n",
    "# If you haven't cloned it, use: pip install git+https://github.com/safety-research/bloom.git\n",
    "!pip install -e ./bloom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Bloom requires API keys for the LLM providers you want to use. Set these as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API keys (uncomment and fill in as needed)\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-key\"\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\"\n",
    "# os.environ[\"OPENROUTER_API_KEY\"] = \"your-openrouter-key\"\n",
    "\n",
    "# Or load from a .env file\n",
    "from pathlib import Path\n",
    "\n",
    "env_file = Path(\".env\")\n",
    "if env_file.exists():\n",
    "    with open(env_file) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith(\"#\") and \"=\" in line:\n",
    "                key, value = line.split(\"=\", 1)\n",
    "                os.environ[key.strip()] = value.strip().strip('\"').strip(\"'\")\n",
    "    print(\"Loaded environment variables from .env\")\n",
    "else:\n",
    "    print(\"No .env file found - make sure API keys are set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Four-Stage Pipeline\n",
    "\n",
    "Bloom's evaluation pipeline consists of four stages:\n",
    "\n",
    "1. **Understanding**: Analyzes behavior descriptions and example transcripts to establish measurement context\n",
    "2. **Ideation**: Generates evaluation scenarios (situations, simulated users, system prompts, environments)\n",
    "3. **Rollout**: Executes scenarios in parallel, simulating user and tool responses\n",
    "4. **Judgment**: Scores transcripts for behavior presence; meta-judge produces suite-level analysis\n",
    "\n",
    "Let's explore each stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a Workspace\n",
    "\n",
    "First, let's initialize a Bloom workspace which creates the configuration files we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bloom workspace (creates bloom-data/ directory with config files)\n",
    "!bloom init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates:\n",
    "- `bloom-data/seed.yaml` - Main configuration file\n",
    "- `bloom-data/models.json` - Model ID mappings\n",
    "- `bloom-data/behaviors.json` - Behavior definitions\n",
    "- `.env` - Template for API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Configuration\n",
    "\n",
    "Let's look at the seed configuration that controls the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "seed_path = Path(\"bloom-data/seed.yaml\")\n",
    "if seed_path.exists():\n",
    "    with open(seed_path) as f:\n",
    "        seed_config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"=== Seed Configuration ===\")\n",
    "    print(yaml.dump(seed_config, default_flow_style=False, sort_keys=False))\n",
    "else:\n",
    "    print(\"Run 'bloom init' first to create the configuration files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Configuration Parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `behavior.name` | Target behavior (e.g., \"sycophancy\", \"self-preservation\") |\n",
    "| `behavior.examples` | Example transcripts to guide generation (optional) |\n",
    "| `ideation.total_evals` | Number of scenarios to generate |\n",
    "| `rollout.target` | Model to evaluate (LiteLLM ID or short name) |\n",
    "| `rollout.modality` | \"conversation\" or \"simenv\" (with tool calls) |\n",
    "| `debug` | Enable verbose output |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Available Behaviors\n",
    "\n",
    "Bloom comes with pre-defined behaviors you can evaluate. Let's see what's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloom.data import get_bundled_behaviors, list_bundled_examples\n",
    "\n",
    "# List all bundled behaviors\n",
    "behaviors = get_bundled_behaviors()\n",
    "print(\"=== Available Behaviors ===\")\n",
    "for name, description in behaviors.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    if isinstance(description, dict):\n",
    "        print(f\"  {description.get('description', 'No description')[:100]}...\")\n",
    "    else:\n",
    "        print(f\"  {str(description)[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List example transcripts for behaviors\n",
    "print(\"=== Available Example Transcripts ===\")\n",
    "examples = list_bundled_examples()\n",
    "for example in examples:\n",
    "    print(f\"  - {example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Pipeline Programmatically\n",
    "\n",
    "You can run Bloom either via CLI or programmatically. Here's how to use the Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloom.utils import load_config\n",
    "\n",
    "# Load the configuration\n",
    "config = load_config(\"bloom-data/seed.yaml\")\n",
    "print(f\"Loaded config for behavior: {config.get('behavior', {}).get('name', 'unknown')}\")\n",
    "print(f\"Target model: {config.get('rollout', {}).get('target', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Individual Stages\n",
    "\n",
    "You can run stages individually for more control. This is useful for:\n",
    "- Debugging specific stages\n",
    "- Reusing understanding/ideation across multiple models\n",
    "- Resuming from a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import individual stages\n",
    "from bloom.stages.step1_understanding import run_understanding\n",
    "from bloom.stages.step2_ideation import run_ideation\n",
    "from bloom.stages.step3_rollout import run_rollout\n",
    "from bloom.stages.step4_judgment import run_judgment\n",
    "\n",
    "print(\"Stage functions imported successfully\")\n",
    "print(\"\\nTo run a stage:\")\n",
    "print(\"  run_understanding(config=config, config_dir='bloom-data')\")\n",
    "print(\"  run_ideation(config=config, config_dir='bloom-data')\")\n",
    "print(\"  await run_rollout(config=config, config_dir='bloom-data')  # async\")\n",
    "print(\"  await run_judgment(config=config, config_dir='bloom-data')  # async\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Full Pipeline\n",
    "\n",
    "For a complete evaluation, use `run_pipeline` which orchestrates all stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloom.core import run_pipeline\n",
    "\n",
    "# Uncomment to run the full pipeline (requires API keys and will make API calls)\n",
    "# run_pipeline(config=config, config_dir=\"bloom-data\")\n",
    "\n",
    "print(\"To run the full pipeline, uncomment the line above.\")\n",
    "print(\"Or use the CLI: bloom run bloom-data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLI Commands Reference\n",
    "\n",
    "Bloom provides a comprehensive CLI for running evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available commands\n",
    "!bloom --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common CLI Commands\n",
    "\n",
    "```bash\n",
    "# Initialize workspace\n",
    "bloom init\n",
    "\n",
    "# Run full pipeline\n",
    "bloom run bloom-data\n",
    "bloom run bloom-data --debug  # verbose output\n",
    "\n",
    "# Run individual stages\n",
    "bloom understanding bloom-data\n",
    "bloom ideation bloom-data\n",
    "bloom rollout bloom-data\n",
    "bloom judgment bloom-data\n",
    "\n",
    "# Interactive chat (for testing models)\n",
    "bloom chat --model anthropic/claude-sonnet-4-20250514\n",
    "bloom chat --model openai/gpt-4o --reasoning-effort high\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Configuring an Evaluation\n",
    "\n",
    "Let's create a simple configuration to evaluate a model for sycophancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Example configuration for evaluating sycophancy\n",
    "example_config = {\n",
    "    \"behavior\": {\n",
    "        \"name\": \"sycophancy\",\n",
    "        \"examples\": [\"sycophancy/ethical\", \"sycophancy/factual\"]  # optional\n",
    "    },\n",
    "    \"ideation\": {\n",
    "        \"total_evals\": 10,  # number of scenarios to generate\n",
    "    },\n",
    "    \"rollout\": {\n",
    "        \"target\": \"anthropic/claude-sonnet-4-20250514\",  # model to evaluate\n",
    "        \"modality\": \"conversation\",  # or \"simenv\" for tool-use scenarios\n",
    "    },\n",
    "    \"debug\": True  # enable verbose output\n",
    "}\n",
    "\n",
    "print(\"=== Example Sycophancy Evaluation Config ===\")\n",
    "print(yaml.dump(example_config, default_flow_style=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Results\n",
    "\n",
    "Results are saved to `bloom-results/{behavior_name}/`. You can view transcripts using the bloom-viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "results_dir = Path(\"bloom-results\")\n",
    "if results_dir.exists():\n",
    "    print(\"=== Available Results ===\")\n",
    "    for behavior_dir in results_dir.iterdir():\n",
    "        if behavior_dir.is_dir():\n",
    "            print(f\"\\n{behavior_dir.name}/\")\n",
    "            for file in sorted(behavior_dir.iterdir())[:5]:  # show first 5 files\n",
    "                print(f\"  - {file.name}\")\n",
    "            remaining = len(list(behavior_dir.iterdir())) - 5\n",
    "            if remaining > 0:\n",
    "                print(f\"  ... and {remaining} more files\")\n",
    "else:\n",
    "    print(\"No results yet. Run 'bloom run bloom-data' to generate results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view results with the interactive viewer:\n",
    "# npx @isha-gpt/bloom-viewer --port 8080 --dir ./bloom-results\n",
    "\n",
    "print(\"To view results interactively, run:\")\n",
    "print(\"  npx @isha-gpt/bloom-viewer --port 8080 --dir ./bloom-results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Bloom's Orchestrators\n",
    "\n",
    "Bloom uses two types of orchestrators to manage conversations:\n",
    "\n",
    "1. **ConversationOrchestrator**: Basic text-based conversations\n",
    "2. **SimEnvOrchestrator**: Simulated environment with tool/function calling\n",
    "\n",
    "The orchestrator is selected based on the `rollout.modality` setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bloom.orchestrators.ConversationOrchestrator import ConversationOrchestrator\n",
    "from bloom.orchestrators.SimEnvOrchestrator import SimEnvOrchestrator\n",
    "\n",
    "print(\"ConversationOrchestrator: For basic conversation evaluations\")\n",
    "print(\"  - Text-based exchanges between evaluator and target model\")\n",
    "print(\"  - No tool support\")\n",
    "print()\n",
    "print(\"SimEnvOrchestrator: For tool-use evaluations\")\n",
    "print(\"  - Supports function/tool calling\")\n",
    "print(\"  - Simulates tool responses dynamically\")\n",
    "print(\"  - Use modality: 'simenv' in config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Behaviors\n",
    "\n",
    "Anthropic has released benchmark results across 16 frontier models for these behaviors:\n",
    "\n",
    "- **Delusional sycophancy**: Model agrees with demonstrably false user beliefs\n",
    "- **Instructed long-horizon sabotage**: Model follows instructions to subtly sabotage\n",
    "- **Self-preservation**: Model takes actions to prevent being modified or shut down\n",
    "- **Self-preferential bias**: Model favors its own outputs over others\n",
    "\n",
    "You can use these as starting points for your own evaluations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Configure your evaluation**: Edit `bloom-data/seed.yaml` to target a specific behavior\n",
    "2. **Set API keys**: Add your keys to `.env` and run `source .env`\n",
    "3. **Run the pipeline**: `bloom run bloom-data --debug`\n",
    "4. **View results**: Use the bloom-viewer or examine JSON files directly\n",
    "5. **Scale with W&B**: Use sweep configs from `bloom/examples/sweeps/` for large experiments\n",
    "\n",
    "For more details, see the [Bloom README](https://github.com/safety-research/bloom) and [technical documentation](https://alignment.anthropic.com/2025/bloom-auto-evals/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
